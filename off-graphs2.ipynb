{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fr.openfoodfacts.org.products.csv', 'world-food-facts.zip', 'en.openfoodfacts.org.products.tsv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from importlib import reload # for reloading modules after a script has been modified\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# import plotly.offline as py\n",
    "# py.init_notebook_mode(connected=True)\n",
    "# import plotly.graph_objs as go\n",
    "sns.set()\n",
    "\n",
    "# from PIL import Image\n",
    "# from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"data\"))\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD, FastICA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import metric_learn\n",
    "\n",
    "PUNCTUATION_REGEX = re.compile(r\"\"\"[:,;.&~\"'|`_\\\\={}%()\\[\\]]+\"\"\")\n",
    "DIGIT_REGEX = re.compile(r\"[0-9]+\")\n",
    "MULTIPLE_SPACES_REGEX = re.compile(r\" +\")\n",
    "\n",
    "def preprocess(text):\n",
    "    text = PUNCTUATION_REGEX.sub(' ', text)\n",
    "    text = DIGIT_REGEX.sub(' ', text)\n",
    "    return MULTIPLE_SPACES_REGEX.sub(' ', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>categories</th>\n",
       "      <th>categories_tags</th>\n",
       "      <th>countries_tags</th>\n",
       "      <th>ingredients_text</th>\n",
       "      <th>carbon-footprint_100g</th>\n",
       "      <th>nutrition-score-fr_100g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vitória crackers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en:france</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cacao</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en:france</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sauce Sweety chili 0%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en:france</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mini coco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en:france</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pistou d'ail des ours</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en:france</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            product_name categories categories_tags countries_tags ingredients_text  carbon-footprint_100g  nutrition-score-fr_100g\n",
       "0       Vitória crackers        NaN             NaN      en:france              NaN                    NaN                      NaN\n",
       "1                  Cacao        NaN             NaN      en:france              NaN                    NaN                      NaN\n",
       "2  Sauce Sweety chili 0%        NaN             NaN      en:france              NaN                    NaN                      NaN\n",
       "3              Mini coco        NaN             NaN      en:france              NaN                    NaN                      NaN\n",
       "4  Pistou d'ail des ours        NaN             NaN      en:france              NaN                    NaN                      NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/fr.openfoodfacts.org.products.csv\",\n",
    "                       delimiter='\\t',\n",
    "                       encoding='utf-8',\n",
    "                         nrows = 300000,\n",
    "                      usecols=['product_name', \n",
    "                               'ingredients_text', \n",
    "                               'nutrition-score-fr_100g', 'carbon-footprint_100g', \n",
    "                             #  'energy_100g', 'fat_100g', \n",
    "                             #  'carbohydrates_100g', 'sugars_100g', 'proteins_100g', 'salt_100g', 'sodium_100g',\n",
    "                              'categories_tags','countries_tags','categories'\n",
    "                              ],\n",
    "                      converters={'categories_tags': lambda x: x.split(',') if x else np.NaN}\n",
    "                      )\n",
    "df.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[pd.notnull(df['categories_tags'])]\n",
    "df = df[pd.notnull(df['ingredients_text'])]\n",
    "# df = df[pd.notnull(df['carbon-footprint_100g'])]\n",
    "\n",
    "\n",
    "fr_df = df[df['countries_tags'] == 'en:france']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21140 elements in original dataframe, 15615 after category filter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/miniconda3/envs/basics/lib/python3.6/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "selected_categories = [\n",
    "    \"en:beverages\",\n",
    "    \"en:sugary-snacks\",\n",
    "    \"en:meals\",\n",
    "    \"en:dairies\",\n",
    "    \"en:meats\",\n",
    "    \"en:desserts\",\n",
    "    \"en:frozen-foods\",\n",
    "    \"en:breakfasts\",\n",
    "    \"en:cheeses\",\n",
    "    \"en:biscuits\",\n",
    "    \"en:groceries\",\n",
    "    \"en:fats\",\n",
    "    \"en:chocolates\",\n",
    "    \"en:sauces\",\n",
    "]\n",
    "\n",
    "selected_categories_set = set(selected_categories)\n",
    "\n",
    "criterion = fr_df['categories_tags'].map(lambda x: bool(set(x).intersection(selected_categories_set)))\n",
    "cat_df = fr_df[criterion]\n",
    "cat_df['categories_tags_int'] = fr_df['categories_tags'].map(lambda categories: [selected_categories.index(x) for x in categories if x in selected_categories])\n",
    "print(f\"{len(fr_df)} elements in original dataframe, {len(cat_df)} after category filter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>categories</th>\n",
       "      <th>categories_tags</th>\n",
       "      <th>countries_tags</th>\n",
       "      <th>ingredients_text</th>\n",
       "      <th>carbon-footprint_100g</th>\n",
       "      <th>nutrition-score-fr_100g</th>\n",
       "      <th>categories_tags_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>Blanquette de Volaille et son Riz</td>\n",
       "      <td>Plats préparés, Produits à la viande, Plats à ...</td>\n",
       "      <td>[en:meals, en:meat-based-products, en:meals-wi...</td>\n",
       "      <td>en:france</td>\n",
       "      <td>Riz précuit 40,4 % (eau, riz, huile de colza, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>Entremets Crème Brulée</td>\n",
       "      <td>Produits laitiers, Desserts, Produits déshydra...</td>\n",
       "      <td>[en:dairies, en:desserts, en:dried-products, e...</td>\n",
       "      <td>en:france</td>\n",
       "      <td>Sucre, poudre de _lait_, poudre au beurre (_la...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[3, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Biscuits sablés fourrage au cacao</td>\n",
       "      <td>Snacks sucrés, Biscuits et gâteaux, Biscuits, ...</td>\n",
       "      <td>[en:sugary-snacks, en:biscuits-and-cakes, en:b...</td>\n",
       "      <td>en:france</td>\n",
       "      <td>Sucre, farine de _Blé_, graisse et huiles végé...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>A&amp;w - Root Beer - 355ml</td>\n",
       "      <td>Boissons</td>\n",
       "      <td>[en:beverages, en:non-alcoholic-beverages]</td>\n",
       "      <td>en:france</td>\n",
       "      <td>Eau gazéifiée, sirop de mais riche en fructose...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>Compote de Pomme</td>\n",
       "      <td>Aliments et boissons à base de végétaux, Alime...</td>\n",
       "      <td>[en:plant-based-foods-and-beverages, en:plant-...</td>\n",
       "      <td>en:france</td>\n",
       "      <td>Flocons de pommes 76 % (pomme, amidon de maïs,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          product_name                                         categories                                    categories_tags countries_tags                                   ingredients_text  carbon-footprint_100g  nutrition-score-fr_100g categories_tags_int\n",
       "260  Blanquette de Volaille et son Riz  Plats préparés, Produits à la viande, Plats à ...  [en:meals, en:meat-based-products, en:meals-wi...      en:france  Riz précuit 40,4 % (eau, riz, huile de colza, ...                    NaN                      0.0                 [2]\n",
       "276             Entremets Crème Brulée  Produits laitiers, Desserts, Produits déshydra...  [en:dairies, en:desserts, en:dried-products, e...      en:france  Sucre, poudre de _lait_, poudre au beurre (_la...                    NaN                      2.0              [3, 5]\n",
       "307  Biscuits sablés fourrage au cacao  Snacks sucrés, Biscuits et gâteaux, Biscuits, ...  [en:sugary-snacks, en:biscuits-and-cakes, en:b...      en:france  Sucre, farine de _Blé_, graisse et huiles végé...                    NaN                      NaN              [1, 9]\n",
       "309            A&w - Root Beer - 355ml                                           Boissons         [en:beverages, en:non-alcoholic-beverages]      en:france  Eau gazéifiée, sirop de mais riche en fructose...                    NaN                     16.0                 [0]\n",
       "313                   Compote de Pomme  Aliments et boissons à base de végétaux, Alime...  [en:plant-based-foods-and-beverages, en:plant-...      en:france  Flocons de pommes 76 % (pomme, amidon de maïs,...                    NaN                      1.0                 [5]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [np.array(c) for c in cat_df['categories_tags_int'].values] # several categories per sample\n",
    "y = MultiLabelBinarizer().fit_transform(target) # one-hot of the targets\n",
    "X = cat_df.ingredients_text.values\n",
    "\n",
    "target = np.argmax(y,axis=1) # trivial reduce to 1 category per sample (loss of information)\n",
    "\n",
    "idx_shuffle = np.random.permutation(X.shape[0])\n",
    "X = X[idx_shuffle]\n",
    "y = y[idx_shuffle,:]\n",
    "\n",
    "idx_train = np.arange(1000)\n",
    "idx_test = np.arange(1000,2000,1)\n",
    "idx_both = np.concatenate([idx_train,idx_test],axis=0)\n",
    "X_train = X[idx_train]\n",
    "X_test = X[idx_test]\n",
    "target_train = target[idx_train]\n",
    "target_test = target[idx_test]\n",
    "y_train = y[idx_train,:]\n",
    "y_test = y[idx_test,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative HFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition_learner = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(strip_accents='unicode', min_df=5, preprocessor=preprocess)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('pca', TruncatedSVD(64))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_proj = decomposition_learner.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import large_algos as lalg\n",
    "from importlib import reload\n",
    "reload(lalg)\n",
    "\n",
    "pred,f = lalg.iterative_hfs(samples=X_proj[idx_both,:],\n",
    "                            idx_lbl=idx_train,\n",
    "                            labels_binary=y[idx_train,:], \n",
    "                              var=0.000001, eps=0, k=5, \n",
    "                          niter = 3, laplacian_regularization=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.205"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[[idx_test,pred[idx_test]]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incremental centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-212-ac28494dfb51>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-212-ac28494dfb51>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    incremental_k_centers(labeled_samples=X_proj[:2000,:, labels)\u001b[0m\n\u001b[0m                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from large_algos import incremental_k_centers\n",
    "\n",
    "incremental_k_centers(labeled_samples=X_proj[:2000,:], labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 1),\n",
       "        preprocessor=<function preprocess a..._class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "          n_jobs=None))])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(strip_accents='unicode', min_df=5, preprocessor=preprocess)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('pca', TruncatedSVD(64)), # try with\n",
    "    ('clf', OneVsRestClassifier(LinearSVC()))\n",
    "])\n",
    "\n",
    "classifier.fit(X[idx_train], y[idx_train,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    en:beverages       0.90      0.64      0.74       174\n",
      "en:sugary-snacks       0.87      0.84      0.86       219\n",
      "        en:meals       0.84      0.65      0.73       127\n",
      "      en:dairies       0.97      0.85      0.90       170\n",
      "        en:meats       0.96      0.66      0.78       138\n",
      "     en:desserts       0.71      0.36      0.48        69\n",
      " en:frozen-foods       0.00      0.00      0.00        34\n",
      "   en:breakfasts       0.97      0.50      0.66        70\n",
      "      en:cheeses       0.97      0.77      0.86        90\n",
      "     en:biscuits       0.86      0.54      0.67        57\n",
      "    en:groceries       0.88      0.12      0.21        58\n",
      "         en:fats       0.00      0.00      0.00        31\n",
      "   en:chocolates       0.71      0.34      0.46        44\n",
      "       en:sauces       0.60      0.09      0.16        32\n",
      "\n",
      "       micro avg       0.90      0.61      0.72      1313\n",
      "       macro avg       0.73      0.45      0.54      1313\n",
      "    weighted avg       0.84      0.61      0.69      1313\n",
      "     samples avg       0.66      0.61      0.62      1313\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/miniconda3/envs/basics/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lucas/miniconda3/envs/basics/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lucas/miniconda3/envs/basics/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lucas/miniconda3/envs/basics/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X[idx_test])\n",
    "print(classification_report(y[idx_test,:], y_pred, target_names=selected_categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA + Metric_learn + clf (LinearSVC / kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All intermediate steps should be transformers and implement fit and transform. 'TSNE(angle=0.5, early_exaggeration=12.0, init='random', learning_rate=200.0,\n   method='barnes_hut', metric='euclidean', min_grad_norm=1e-07,\n   n_components=64, n_iter=1000, n_iter_without_progress=300,\n   perplexity=30.0, random_state=None, verbose=0)' (type <class 'sklearn.manifold.t_sne.TSNE'>) doesn't",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-ca593a2395ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'tsne'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m#  ('pca', TruncatedSVD(64)), # need this to transform above obtained sparse matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0;34m'metric_decomp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_learn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLFDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membedding_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# does not impact the results much\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;31m#  ('metric_decomp', metric_learn.LMNN(k=5,learn_rate=1e-5,min_iter=1,max_iter=3))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;31m#  ('metric_decomp', metric_learn.NCA(max_iter=10))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/basics/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, steps, memory)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/basics/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_validate_steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 raise TypeError(\"All intermediate steps should be \"\n\u001b[1;32m    166\u001b[0m                                 \u001b[0;34m\"transformers and implement fit and transform.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                                 \" '%s' (type %s) doesn't\" % (t, type(t)))\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# We allow last estimator to be None as an identity transformation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: All intermediate steps should be transformers and implement fit and transform. 'TSNE(angle=0.5, early_exaggeration=12.0, init='random', learning_rate=200.0,\n   method='barnes_hut', metric='euclidean', min_grad_norm=1e-07,\n   n_components=64, n_iter=1000, n_iter_without_progress=300,\n   perplexity=30.0, random_state=None, verbose=0)' (type <class 'sklearn.manifold.t_sne.TSNE'>) doesn't"
     ]
    }
   ],
   "source": [
    "decomposition_learner = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(strip_accents='unicode', min_df=5, preprocessor=preprocess)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('pca', TruncatedSVD(64)), # need this to transform above obtained sparse matrix\n",
    "    ('metric_decomp', metric_learn.LFDA(k=8,embedding_type='weighted')) # does not impact the results much\n",
    "  #  ('metric_decomp', metric_learn.LMNN(k=5,learn_rate=1e-5,min_iter=1,max_iter=3))\n",
    "  #  ('metric_decomp', metric_learn.NCA(max_iter=10))\n",
    "])\n",
    "\n",
    "X_proj = decomposition_learner.fit_transform(np.concatenate([X_train,X_test],axis=0),\n",
    "                                            np.concatenate([target_train,target_test],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Pipeline([\n",
    "  #  ('clf', OneVsRestClassifier(LinearSVC())),\n",
    "    ('clf', KNeighborsClassifier(n_neighbors=5))\n",
    "])\n",
    "\n",
    "classifier.fit(X_proj[idx_train],y_train)\n",
    "pred = classifier.predict(X_proj[idx_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    en:beverages       0.70      0.58      0.64       183\n",
      "en:sugary-snacks       0.89      0.73      0.80       231\n",
      "        en:meals       0.64      0.64      0.64       123\n",
      "      en:dairies       0.91      0.77      0.84       182\n",
      "        en:meats       0.86      0.77      0.81       124\n",
      "     en:desserts       0.69      0.29      0.41        86\n",
      " en:frozen-foods       0.00      0.00      0.00        33\n",
      "   en:breakfasts       0.76      0.40      0.53        62\n",
      "      en:cheeses       0.82      0.76      0.79        93\n",
      "     en:biscuits       0.66      0.42      0.51        60\n",
      "    en:groceries       0.71      0.33      0.45        72\n",
      "         en:fats       0.50      0.07      0.12        29\n",
      "   en:chocolates       0.81      0.63      0.71        46\n",
      "       en:sauces       0.73      0.31      0.43        36\n",
      "\n",
      "       micro avg       0.79      0.59      0.68      1360\n",
      "       macro avg       0.69      0.48      0.55      1360\n",
      "    weighted avg       0.76      0.59      0.65      1360\n",
      "     samples avg       0.63      0.60      0.60      1360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/miniconda3/envs/basics/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lucas/miniconda3/envs/basics/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lucas/miniconda3/envs/basics/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/lucas/miniconda3/envs/basics/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred, target_names=selected_categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline : tfidf + LinearSVC\n",
    "\n",
    "- baseline\n",
    "```\n",
    "       micro avg       0.90      0.68      0.77      1313\n",
    "       macro avg       0.85      0.55      0.64      1313\n",
    "    weighted avg       0.88      0.68      0.75      1313\n",
    "     samples avg       0.72      0.68      0.69      1313\n",
    "```\n",
    "- tfidf + pca + LinearSVC\n",
    "```\n",
    "       micro avg       0.90      0.60      0.72      1313\n",
    "       macro avg       0.79      0.45      0.53      1313\n",
    "    weighted avg       0.86      0.60      0.68      1313\n",
    "     samples avg       0.66      0.61      0.62      1313\n",
    "```\n",
    "- tfidf + pca + kNN\n",
    "```\n",
    "       micro avg       0.84      0.64      0.73      1360\n",
    "       macro avg       0.83      0.55      0.63      1360\n",
    "    weighted avg       0.84      0.64      0.72      1360\n",
    "     samples avg       0.69      0.65      0.66      1360\n",
    "```\n",
    "### Metric learning : tfidf + TruncSVD(64) + metric + kNN\n",
    "- LMNN(k=5,learn_rate=1e-5,min_iter=1,max_iter=3)\n",
    "```\n",
    "       micro avg       0.81      0.65      0.72      1360\n",
    "       macro avg       0.71      0.54      0.60      1360\n",
    "    weighted avg       0.78      0.65      0.70      1360\n",
    "     samples avg       0.68      0.66      0.66      1360\n",
    "```\n",
    "- LFDA(k=8,embedding_type='weighted')\n",
    "```\n",
    "       micro avg       0.83      0.59      0.69      1360\n",
    "       macro avg       0.84      0.50      0.59      1360\n",
    "    weighted avg       0.84      0.59      0.67      1360\n",
    "     samples avg       0.64      0.60      0.61      1360\n",
    "```\n",
    "- NCA(max_iter=10)\n",
    "```\n",
    "       micro avg       0.79      0.59      0.68      1360\n",
    "       macro avg       0.69      0.48      0.55      1360\n",
    "    weighted avg       0.76      0.59      0.65      1360\n",
    "     samples avg       0.63      0.60      0.60      1360\n",
    "```\n",
    "### Metric learning : tfidf + TruncSVD(64) + metric + LinearSVC\n",
    "\n",
    "- LMNN(k=5,learn_rate=1e-5,min_iter=1,max_iter=3)\n",
    "```\n",
    "       micro avg       0.88      0.67      0.76      1313\n",
    "       macro avg       0.83      0.54      0.63      1313\n",
    "    weighted avg       0.87      0.67      0.74      1313\n",
    "     samples avg       0.69      0.67      0.67      1313\n",
    "```\n",
    "- LFDA(k=8,embedding_type='weighted')\n",
    "```\n",
    "       micro avg       0.92      0.62      0.74      1313\n",
    "       macro avg       0.83      0.48      0.57      1313\n",
    "    weighted avg       0.89      0.62      0.71      1313\n",
    "     samples avg       0.68      0.63      0.64      1313\n",
    "```\n",
    "- NCA(max_iter=3)\n",
    "```\n",
    "       micro avg       0.86      0.68      0.76      1313\n",
    "       macro avg       0.76      0.56      0.62      1313\n",
    "    weighted avg       0.83      0.68      0.74      1313\n",
    "     samples avg       0.70      0.68      0.68      1313\n",
    "```\n",
    "- NCA(max_iter=10)\n",
    "```\n",
    "       micro avg       0.73      0.70      0.72      1313\n",
    "       macro avg       0.69      0.61      0.62      1313\n",
    "    weighted avg       0.78      0.70      0.72      1313\n",
    "     samples avg       0.66      0.71      0.66      1313\n",
    "```\n",
    "- NCA(max_iter=10) LinearSVC(maxiter=30000)\n",
    "```\n",
    "       micro avg       0.78      0.69      0.73      1313\n",
    "       macro avg       0.67      0.58      0.62      1313\n",
    "    weighted avg       0.77      0.69      0.73      1313\n",
    "     samples avg       0.69      0.70      0.67      1313\n",
    "```\n",
    "- \n",
    "```\n",
    "```\n",
    "- \n",
    "```\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "carbon footprint :\n",
    "- chercher un algo regression qui puisse utiliser entrées sparse\n",
    "- comparer avec PCA + LMNN + (log ?) regression\n",
    "\n",
    "\n",
    "NOTES\n",
    "\n",
    "PCA appears to be a bad decomposer (LinearSVC loses drastic performances) yet it is an simple algorithm to extract information from large scale sparse matrices for algorithms that cannot work on such large matrices\n",
    "\n",
    "We try and find the best decomposer based on the categorization problem to then use it for the carbon footprint regression problem.\n",
    "\n",
    "We find that PCA+LMNN is a good decomposer, giving results very close to LinearSVC for categorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
